Проект: ETL-пайплайн для загрузки данных о поверках СИ
Описание проекта

Проект представляет собой ETL-пайплайн для загрузки, обработки и хранения данных о поверках средств измерений (СИ) с портала ФГИС "Аршин". Данные предоставляются в формате CSV, упакованные в ZIP-архивы, и включают как полные снимки (snapshots), так и инкрементальные обновления (deltas).

Основные задачи проекта:

    Парсинг данных из CSV-файлов.

    Загрузка данных в RAW-слой базы данных PostgreSQL.

    Очистка и трансформация данных.

    Загрузка данных в Core-слой или витрины.

    Автоматизация процессов с использованием Apache Airflow.

    Экспорт данных в формат, удобный для конечного пользователя (например, XLSX).

Структура проекта
Copy

fgis_poverki_etl/
├── README.md                       # Описание проекта
├── requirements.txt                # Зависимости Python
├── .env                            # Переменные окружения
├── .gitignore                      # Игнорируемые файлы для Git
├── docker-compose.yml              # Конфигурация Docker Compose
├── Dockerfile                      # Dockerfile для сборки образа
├── scripts/                        # Вспомогательные скрипты
├── data/                           # Директория для данных
├── logs/                           # Логи приложения
├── airflow/                        # Конфигурация Airflow
├── src/                            # Исходный код проекта
└── tests/                          # Тесты

Подробное описание структуры директорий см. в документации.
Технологический стек

    Язык программирования: Python 3.12

    База данных: PostgreSQL

    Оркестрация: Apache Airflow

    Библиотеки:

        pandas — обработка данных.

        requests — загрузка файлов.

        psycopg2 — работа с PostgreSQL.

        sqlalchemy — ORM для работы с БД. (предположительно)

        openpyxl — экспорт данных в XLSX.

        alembic — управление миграциями БД. (предположительно)

    Инфраструктура: (предположительно/желательно)

        Docker

        Docker Compose

Установка и настройка

(сюда мне пока нечего вставить)

Автоматизация с помощью Airflow

Airflow используется для автоматизации ETL-процессов. DAG-файлы находятся в директории airflow/dags/.

(подробнее расписать по реализации)

Тестирование
(быть должно, но не знаю как)

Документация

(даже не знаю что сюда потом вставить О_о)

З.Ы. Если вы это прочитли: приношу извинения за бесполезно потраченное время!=)